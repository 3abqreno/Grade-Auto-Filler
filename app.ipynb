{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import skimage.io as io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.exposure import histogram\n",
    "from matplotlib.pyplot import bar\n",
    "from skimage.color import rgb2gray,rgb2hsv\n",
    "from pathlib import Path\n",
    "# Convolution:\n",
    "from scipy.signal import convolve2d\n",
    "from scipy import fftpack\n",
    "import math\n",
    "from functools import cmp_to_key\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import median\n",
    "from skimage.feature import canny\n",
    "import commonfunctions as cf # this a custom module found the commonfunctions.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Edges\n",
    "from skimage.filters import sobel_h, sobel, sobel_v,roberts, prewitt\n",
    "\n",
    "# Show the figures / plots inside the notebook\n",
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show() \n",
    "\n",
    "\n",
    "def showHist(img):\n",
    "    # An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "    plt.figure()\n",
    "    imgHist = histogram(img, nbins=256)\n",
    "    \n",
    "    bar(imgHist[1].astype(np.uint8), imgHist[0], width=0.8, align='center')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr=[[] for _ in range (6)]\n",
    "def readImage(imgpath):\n",
    "    img=cv2.imread(imgpath)\n",
    "    transformed_img = perspective_transform(img, 0)\n",
    "    inverted_img=invert_image(transformed_img)\n",
    "    show_images([inverted_img])\n",
    "    return inverted_img\n",
    "def getVerticalLines(inverted_img):\n",
    "    # Apply edge detection using Canny edge detector\n",
    "    edges = cv2.Canny(inverted_img, 50, 150, apertureSize=3)\n",
    "    # Perform Hough Line Transform for vertical lines\n",
    "    rho = 1  # 1 pixel\n",
    "    theta = np.pi # Vertical lines (90 degrees)\n",
    "    threshold = 260  # Adjust this value as needed\n",
    "    min_line_length = 160  # Minimum line length\n",
    "    max_line_gap = 20  # Maximum allowed gap between line segments\n",
    "\n",
    "    lines = cv2.HoughLinesP(edges, rho=rho, theta=theta, threshold=threshold,\n",
    "                            minLineLength=min_line_length, maxLineGap=max_line_gap)\n",
    "    sorted_lines = sorted(lines, key=lambda line: line[0][0])\n",
    "    print(\"from vertical lines\",sorted_lines)\n",
    "    filtered_lines = [sorted_lines[0]]\n",
    "    for line in sorted_lines[1:]:\n",
    "        prev_x = filtered_lines[-1][0][0] \n",
    "        cur_x = line[0][0]  \n",
    "\n",
    "        if cur_x - prev_x >= 20:\n",
    "            filtered_lines.append(line)  \n",
    "    return filtered_lines\n",
    "def getBlocks(lines,cur_Seg,inverted_img):\n",
    "    x1=lines[0][0][0]\n",
    "    idx=0\n",
    "    for line in lines:\n",
    "        x2=line[0][0]\n",
    "        if(x2-x1>cur_Seg[0]):\n",
    "            block = inverted_img[0:4000, x1:x2]\n",
    "            break      \n",
    "        idx=idx+1\n",
    "    y1 = 150\n",
    "    while y1 < block.shape[0]:\n",
    "        cell = block[y1:y1 + 200, :]\n",
    "        show_images([cell])\n",
    "        arr[cur_Seg[1]].append(cell)\n",
    "        y1 += 220\n",
    "    return [block,idx]\n",
    "segs=[[50,0],[100,1],[200,2],[50,3],[50,4],[50,5]]\n",
    "def getImageBlocks(filtered_lines,inverted_img):\n",
    "    idx = 0\n",
    "    block_images = [] \n",
    "    for i in range(len(segs)):\n",
    "        [block, nwidx] = getBlocks(filtered_lines[idx:], segs[i],inverted_img)\n",
    "        idx = idx + nwidx\n",
    "        block_images.append(block)  \n",
    "    return block_images\n",
    "    \n",
    "    \n",
    "samples_dir = './Samples/'\n",
    "for i in range(8, 9):\n",
    "    print(i)\n",
    "    image_path = os.path.join(samples_dir, f\"{i}.jpg\")\n",
    "    inverted_img = readImage(image_path)\n",
    "    filtered_lines = getVerticalLines(inverted_img)\n",
    "    blocks=getImageBlocks(filtered_lines, inverted_img)\n",
    "    # for j in range (0,1):\n",
    "    #     getcells(blocks[j])\n",
    "    block_titles = [f\"Image: {i} - Block {j+1}\" for j in range(len(blocks))]\n",
    "    show_images(blocks, block_titles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_sort(a, b):\n",
    "\n",
    "    br_a = cv2.boundingRect(a)\n",
    "    br_b = cv2.boundingRect(b)\n",
    "\n",
    "    if abs(br_a[0] - br_b[0]) <= 5:\n",
    "        return br_a[1] - br_b[1]\n",
    "\n",
    "    return br_a[0] - br_b[0]\n",
    "\n",
    "\n",
    "def sorted_counter (contours):\n",
    "\n",
    "    return sorted(contours, key=cmp_to_key(contour_sort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def largest_contour(contours):\n",
    "    largest_contour = np.array([])\n",
    "    max_area = 0\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.1 * perimeter, True)\n",
    "        if area > max_area and len(approx) == 4:\n",
    "            largest_contour = approx\n",
    "            max_area = area\n",
    "    return largest_contour\n",
    "def Prespective_Transform(img_original):\n",
    "    img =img_original.copy()\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.bilateralFilter(gray_image, 20, 30, 30)\n",
    "\n",
    "    edges = cv2.Canny(gray_image, 20, 120)\n",
    "    edges = cv2.dilate(edges.copy(), None, 2)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    biggest = largest_contour(contours[2:10])\n",
    "    if(biggest.size!=8):\n",
    "        biggest = largest_contour(contours[0:1])\n",
    "    \n",
    "    pts = biggest.reshape(4, 2)\n",
    "\n",
    "    pts_sum = pts.sum(axis=1)\n",
    "\n",
    "    top_left = pts[np.argmin(pts_sum)]\n",
    "    bottom_right = pts[np.argmax(pts_sum)]\n",
    "\n",
    "    pts_diff = np.diff(pts, axis=1)\n",
    "    top_right = pts[np.argmin(pts_diff)]\n",
    "    bottom_left = pts[np.argmax(pts_diff)]\n",
    "\n",
    "\n",
    "    #Image Dimensions\n",
    "    bottom_width = np.sqrt(pow((bottom_right[0] - bottom_left[0]), 2) + (pow((bottom_right[1] - bottom_left[1]), 2)))\n",
    "    top_width = np.sqrt(pow((top_right[0] - top_left[0]), 2) + (pow((top_right[1] - top_left[1]), 2)))\n",
    "    right_height = np.sqrt(pow((top_right[0] - bottom_right[0]), 2) + (pow((top_right[1] - bottom_right[1]), 2)))\n",
    "    left_height = np.sqrt(pow((top_left[0] - bottom_left[0]), 2) + (pow((top_left[1] - bottom_left[1]), 2)))\n",
    "\n",
    "\n",
    "    # Output image size\n",
    "    width = max(int(bottom_width), int(top_width))\n",
    "    height = max(int(right_height), int(left_height))\n",
    "    # Points with new Coordinates \n",
    "    converted_points = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "    arr = np.float32([top_left, top_right, bottom_left, bottom_right])\n",
    "    matrix = cv2.getPerspectiveTransform(arr, converted_points)\n",
    "    img_output = cv2.warpPerspective(img_original, matrix, (width, height))\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from detect_Digits import *\n",
    "def saveImg(directory, suffix, id,img):\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(f\"{directory}/{suffix}_{id}.jpg\", img)\n",
    "def getCells(img):\n",
    "    img_bin = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    (thresh, img_bin) = cv2.threshold(img, 128, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    img_bin = 255 - img_bin\n",
    "\n",
    "    filter_dim = np.array(img).shape[1] // 38\n",
    "    \n",
    "    v_filter = cv2.getStructuringElement(cv2.MORPH_RECT, (1, filter_dim))\n",
    "    h_filter = cv2.getStructuringElement(cv2.MORPH_RECT, (filter_dim, 1))\n",
    "    filter = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    v_lines = cv2.erode(img_bin, v_filter, iterations=3)\n",
    "    v_lines = cv2.dilate(v_lines, v_filter, iterations=3)\n",
    "    lines_ver = cv2.HoughLinesP(v_lines, 1, np.pi / 180, 40, minLineLength=10, maxLineGap=20)\n",
    "\n",
    "    for line in lines_ver:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            v_lines = cv2.line(v_lines, (x1, 0), (x2, v_lines.shape[0]), (255, 255, 255), 1)\n",
    "\n",
    "    h_lines = cv2.erode(img_bin, h_filter, iterations=4)\n",
    "    h_lines = cv2.dilate(h_lines, h_filter, iterations=3)\n",
    "    lines_hor = cv2.HoughLinesP(h_lines, 2, np.pi / 180, 40, minLineLength=5, maxLineGap=10)\n",
    "\n",
    "    for line in lines_hor:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            h_lines = cv2.line(h_lines, (0, y1), (h_lines.shape[1], y2), (255, 255, 255), 1)\n",
    "\n",
    "    final_img = cv2.bitwise_and(v_lines, h_lines)\n",
    "    final_img = cv2.erode(~final_img, filter, iterations=1)\n",
    "    (thresh, img_output) = cv2.threshold(final_img, 128,255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU) \n",
    "    show_images([img_output])\n",
    "    return img_output\n",
    "\n",
    "\n",
    "def cutCells(img, orignal_img,output_dir):\n",
    "    contours = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    contours = sorted_counter(contours)\n",
    "    rows = []\n",
    "\n",
    "    for c in range(len(contours)-1):\n",
    "        x1, y1, w1, h1 = cv2.boundingRect(contours[c])\n",
    "        x2, y2, w2, h2 = cv2.boundingRect(contours[c+1])\n",
    "        \n",
    "        if x1 == x2:\n",
    "            rows.append(y1)\n",
    "        else:\n",
    "            rows.append(y1)\n",
    "            break\n",
    "\n",
    "    num_hor = len(rows)\n",
    "    num_ver = len(contours) \n",
    "    arr=[\"Code\",\"Student Name\",\"English Name\",\"1\",\"2\",\"3\"]\n",
    "    for col in range(0, 6):\n",
    "        for row in range(1, num_hor-1):\n",
    "            x1, y1, w1, h1 = cv2.boundingRect(contours[row+num_hor*col])\n",
    "            x2, y2, w2, h2 = cv2.boundingRect(contours[row+1+num_hor*col])\n",
    "            x3, y3, w3, h3 = cv2.boundingRect(contours[row+num_hor*col+num_hor+1])\n",
    "            new_img = orignal_img[y1+h1:y3, x2+w2:x3]\n",
    "            saveImg(output_dir,arr[col],row,new_img)\n",
    "    # modify to return the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def saveImg(directory, suffix, id,img):\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(f\"{directory}/{suffix}_{id}.jpg\", img)\n",
    "def getCells(img):\n",
    "    img_bin = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    (thresh, img_bin) = cv2.threshold(img, 128, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    img_bin = 255 - img_bin\n",
    "\n",
    "    filter_dim = np.array(img).shape[1] // 38\n",
    "    \n",
    "    v_filter = cv2.getStructuringElement(cv2.MORPH_RECT, (1, filter_dim))\n",
    "    h_filter = cv2.getStructuringElement(cv2.MORPH_RECT, (filter_dim, 1))\n",
    "    filter = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\n",
    "    v_lines = cv2.erode(img_bin, v_filter, iterations=3)\n",
    "    v_lines = cv2.dilate(v_lines, v_filter, iterations=3)\n",
    "    lines_ver = cv2.HoughLinesP(v_lines, 1, np.pi / 180, 40, minLineLength=10, maxLineGap=20)\n",
    "\n",
    "    for line in lines_ver:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            v_lines = cv2.line(v_lines, (x1, 0), (x2, v_lines.shape[0]), (255, 255, 255), 1)\n",
    "\n",
    "    h_lines = cv2.erode(img_bin, h_filter, iterations=4)\n",
    "    h_lines = cv2.dilate(h_lines, h_filter, iterations=3)\n",
    "    lines_hor = cv2.HoughLinesP(h_lines, 2, np.pi / 180, 40, minLineLength=5, maxLineGap=10)\n",
    "\n",
    "    for line in lines_hor:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            h_lines = cv2.line(h_lines, (0, y1), (h_lines.shape[1], y2), (255, 255, 255), 1)\n",
    "\n",
    "    final_img = cv2.bitwise_and(v_lines, h_lines)\n",
    "    final_img = cv2.erode(~final_img, filter, iterations=1)\n",
    "    (thresh, img_output) = cv2.threshold(final_img, 128,255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU) \n",
    "    show_images([img_output])\n",
    "    return img_output\n",
    "\n",
    "\n",
    "def cutCells(img, orignal_img,output_dir):\n",
    "    contours = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    contours = sorted_counter(contours)\n",
    "    rows = []\n",
    "\n",
    "    for c in range(len(contours)-1):\n",
    "        x1, y1, w1, h1 = cv2.boundingRect(contours[c])\n",
    "        x2, y2, w2, h2 = cv2.boundingRect(contours[c+1])\n",
    "        \n",
    "        if x1 == x2:\n",
    "            rows.append(y1)\n",
    "        else:\n",
    "            rows.append(y1)\n",
    "            break\n",
    "\n",
    "    num_hor = len(rows)\n",
    "    num_ver = len(contours) \n",
    "    arr=[\"Code\",\"Student Name\",\"English Name\",\"1\",\"2\",\"3\"]\n",
    "    for col in range(0, 6):\n",
    "        for row in range(1, num_hor-1):\n",
    "            x1, y1, w1, h1 = cv2.boundingRect(contours[row+num_hor*col])\n",
    "            x2, y2, w2, h2 = cv2.boundingRect(contours[row+1+num_hor*col])\n",
    "            x3, y3, w3, h3 = cv2.boundingRect(contours[row+num_hor*col+num_hor+1])\n",
    "            new_img = orignal_img[y1+h1:y3, x2+w2:x3]\n",
    "            # show_images([new_img])\n",
    "            saveImg(output_dir,arr[col],row,new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './Samples'\n",
    "for filename in os.listdir(directory):\n",
    "                filepath = os.path.join(directory, filename)\n",
    "                img = cv2.imread(filepath)\n",
    "                cur_image = Prespective_Transform(img)\n",
    "                gray_image = cv2.cvtColor(cur_image, cv2.COLOR_BGR2GRAY)\n",
    "                img_final = getCells(gray_image)\n",
    "                image_name = os.path.splitext(filename)[0]\n",
    "                output_dir = f\"results/{image_name}\"\n",
    "                cutCells(img_final, gray_image,output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Numebrs_OCR import *\n",
    "# getId_OCR('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl.styles import PatternFill\n",
    "\n",
    "# Sample data\n",
    "ids = [1, 2, 3, 4, 5]  # IDs\n",
    "data_col1 = ['111111', 'B', 'C', 'D', 'E']  # Corresponding data for column 1\n",
    "data_col2 = ['F', 'question', 'empty', 'I', 'J']  # Corresponding data for column 2\n",
    "data_col3 = ['K', 'L', 'M', 'N', 'O']  # Corresponding data for column 3\n",
    "\n",
    "workbook = openpyxl.Workbook()\n",
    "sheet = workbook.active\n",
    "\n",
    "# Set headers for columns\n",
    "sheet['A1'] = 'Code'\n",
    "sheet['B1'] = '1'\n",
    "sheet['C1'] = '2'\n",
    "sheet['D1'] = '3'\n",
    "\n",
    "# Fill the columns with corresponding data and set specific cells to have a red background color\n",
    "for i, id_value in enumerate(ids, start=2):  # Start from row 2 (as 1st row contains headers)\n",
    "    sheet.cell(row=i, column=1, value=id_value)  # Fill IDs in column A\n",
    "    \n",
    "    sheet.cell(row=i, column=2, value=data_col1[i - 2])\n",
    "  \n",
    "    \n",
    "    \n",
    "    if   data_col2[i-2] == 'question':  \n",
    "        red_fill = PatternFill(start_color='FF0000', end_color='FF0000', fill_type='solid')\n",
    "        sheet.cell(row=i, column=3).fill = red_fill  # Set column 3 cell to red\n",
    "    elif data_col2[i-2] != 'empty':\n",
    "      sheet.cell(row=i, column=3, value=data_col2[i - 2])\n",
    "    if   data_col3[i-2] == 'question':  \n",
    "        red_fill = PatternFill(start_color='FF0000', end_color='FF0000', fill_type='solid')\n",
    "        sheet.cell(row=i, column=4).fill = red_fill  \n",
    "    elif data_col3[i-2] != 'empty':\n",
    "        sheet.cell(row=i, column=4, value=data_col3[i - 2])\n",
    "\n",
    "# Save the workbook\n",
    "workbook.save('res.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "def getId_OCR():\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'\n",
    "    img=cv2.imread('./results/1/1_9.jpg')\n",
    "    show_images([img])\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    print(text)\n",
    "    return text    \n",
    "\n",
    "getId_OCR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected handwritten digits:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "# Path to Tesseract executable (change this based on your installation path)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def detect_handwritten_digits(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Perform adaptive thresholding\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "    # Apply morphological transformations (closing) to further clean the image\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    closing = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    # Use pytesseract to perform OCR on the preprocessed image\n",
    "    custom_config = r'--oem 3 --psm 10 outputbase digits'\n",
    "    text = pytesseract.image_to_string(closing, config=custom_config)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Path to your handwritten digits image\n",
    "image_path = 'results/4/1_9.jpg'\n",
    "\n",
    "# Perform handwritten digit detection with enhanced preprocessing and configurations\n",
    "result = detect_handwritten_digits(image_path)\n",
    "\n",
    "print(\"Detected handwritten digits:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
