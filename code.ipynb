{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import commonfunctions as cf # this a custom module found the commonfunctions.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform the perspective transformation\n",
    "def perspective_transform(img,binary):\n",
    "\n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load the image.\")\n",
    "    else:\n",
    "        # Convert the image to grayscale\n",
    "        binary_image=0\n",
    "        if binary==0:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply thresholding to create a binary image\n",
    "            _, binary_image = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY)\n",
    "        else :\n",
    "            binary_image=img\n",
    "        # cf.show_images([binary_image])\n",
    "        # Find contours in the binary image\n",
    "        contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Find the largest contour based on area\n",
    "        print(len(contours))\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        # Approximate the contour to a polygon\n",
    "        epsilon = 0.02 * cv2.arcLength(largest_contour, True)\n",
    "        approx_polygon = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "\n",
    "        # Get the four corners of the polygon\n",
    "        corners = approx_polygon.reshape(-1, 2)\n",
    "        corners = sorted(corners, key=lambda x: x[1])\n",
    "        # Separate the sorted corners into top and bottom\n",
    "        top_corners = sorted(corners[:2], key=lambda x: x[0])\n",
    "        bottom_corners = sorted(corners[2:], key=lambda x: x[0])\n",
    "\n",
    "        # Concatenate the sorted corners\n",
    "        sorted_corners = np.concatenate([bottom_corners, top_corners])\n",
    "\n",
    "        # Define the destination points for the perspective transformation\n",
    "        dst_points = np.float32([[0, img.shape[0]], [img.shape[1], img.shape[0]], [0, 0], [img.shape[1], 0]])\n",
    "\n",
    "        # Calculate the perspective transformation matrix\n",
    "        matrix = cv2.getPerspectiveTransform(sorted_corners.astype(np.float32), dst_points)\n",
    "\n",
    "        # Apply the perspective transformation to the image\n",
    "        warped_img = cv2.warpPerspective(img, matrix, (img.shape[1], img.shape[0]))\n",
    "        return warped_img\n",
    "def perspective_transform_2(binary_image,dilated_img):\n",
    "\n",
    "    if binary_image is None:\n",
    "        print(f\"Error: Unable to load the image.\")\n",
    "    else:\n",
    "        contours, _ = cv2.findContours(dilated_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Find the largest contour based on area\n",
    "        print(len(contours))\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        # Approximate the contour to a polygon\n",
    "        epsilon = 0.02 * cv2.arcLength(largest_contour, True)\n",
    "        approx_polygon = cv2.approxPolyDP(largest_contour, epsilon, True)\n",
    "\n",
    "        # Get the four corners of the polygon\n",
    "        corners = approx_polygon.reshape(-1, 2)\n",
    "        corners = sorted(corners, key=lambda x: x[1])\n",
    "        # Separate the sorted corners into top and bottom\n",
    "        top_corners = sorted(corners[:2], key=lambda x: x[0])\n",
    "        bottom_corners = sorted(corners[2:], key=lambda x: x[0])\n",
    "\n",
    "        # Concatenate the sorted corners\n",
    "        sorted_corners = np.concatenate([bottom_corners, top_corners])\n",
    "        # Define the destination points for the perspective transformation\n",
    "        dst_points = np.float32([[0, binary_image.shape[0]], [binary_image.shape[1], binary_image.shape[0]], [0, 0], [binary_image.shape[1], 0]])\n",
    "\n",
    "        print(sorted_corners)\n",
    "        print(dst_points)\n",
    "        # Calculate the perspective transformation matrix\n",
    "        matrix = cv2.getPerspectiveTransform(sorted_corners.astype(np.float32), dst_points)\n",
    "\n",
    "        # Apply the perspective transformation to the image\n",
    "        warped_binary_image = cv2.warpPerspective(binary_image, matrix, (binary_image.shape[1], binary_image.shape[0]))\n",
    "        return warped_binary_image\n",
    "# # Path to the folder containing images\n",
    "# folder_path = './sample/'\n",
    "\n",
    "# # List all files in the folder\n",
    "# image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "# cnt=0\n",
    "# # Process each image\n",
    "# for image_file in image_files:\n",
    "#     image_path = os.path.join(folder_path, image_file)\n",
    "#     # print(image_path)\n",
    "#     if(cnt==0):\n",
    "#         cf.show_images([perspective_transform(image_path)])\n",
    "#     cnt+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='./sample/sample (15).jpg'\n",
    "alpha = 1.0\n",
    "beta = 0.0\n",
    "img=cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "def invert_image(img):\n",
    "    clone =img\n",
    "    adjusted_img = cv2.addWeighted(img, alpha, np.zeros(img.shape, img.dtype), 0, beta)\n",
    "    # cf.show_images([adjusted_img])\n",
    "    img=perspective_transform(adjusted_img,0)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    thresh_image = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,91, 5)\n",
    "    thresh_image=255-thresh_image\n",
    "    trial = perspective_transform(thresh_image,1)\n",
    "    # cf.show_images([thresh_image])\n",
    "    transform=perspective_transform(thresh_image,1)\n",
    "    return transform\n",
    "\n",
    "def show_bubbels(img):\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    dilated_img = cv2.erode(img, kernel, iterations=1)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    return trial\n",
    "\n",
    "def contour_dilation(img) :\n",
    "     kernel = np.array((1, 10), np.uint8)\n",
    "     img = cv2.dilate(img, kernel, iterations=10)\n",
    "     cf.show_images([img])\n",
    "     print(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_selected(img, kernel) :\n",
    "    # kernel = np.ones((3, 3), np.uint8)\n",
    "    dilated_img = cv2.dilate(img, kernel, iterations=1)\n",
    "    # cf.show_images([dilated_img])\n",
    "\n",
    "    dilated_img = cv2.erode(dilated_img, kernel, iterations=7)\n",
    "    # cf.show_images([dilated_img])\n",
    "\n",
    "    dilated_img = cv2.dilate(dilated_img, kernel, iterations=15)\n",
    "    dilated_img = cv2.erode(dilated_img, kernel, iterations=6)\n",
    "    dilated_img = cv2.dilate(dilated_img, kernel, iterations=8)\n",
    "\n",
    "\n",
    "    return [img,dilated_img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1088\\2131038884.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mbinary_image\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minvert_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdilated_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1088\\1683110541.py\u001b[0m in \u001b[0;36minvert_image\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minvert_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mclone\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0madjusted_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# cf.show_images([adjusted_img])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mperspective_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madjusted_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "image_path='./sample/sample (15).jpg'\n",
    "\n",
    "\n",
    "img=cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "binary_image=invert_image(img)\n",
    "kernel = np.ones((10, 30), np.uint8)\n",
    "dilated_img = cv2.dilate(binary_image, kernel, iterations=12)\n",
    "\n",
    "bubbles=perspective_transform_2(binary_image,dilated_img)\n",
    "cf.show_images([binary_image,dilated_img,bubbles])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "423\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:/a/opencv-python/opencv-python/opencv/modules/imgproc/src/morph.simd.hpp:649: error: (-215:Assertion failed) _kernel.type() == CV_8U in function 'cv::opt_AVX2::`anonymous-namespace'::MorphFilter<struct cv::opt_AVX2::`anonymous namespace'::MaxOp<unsigned char>,struct cv::opt_AVX2::A0x7e9a5f2b::MorphVec<struct cv::opt_AVX2::`anonymous namespace'::VMax<struct cv::hal_AVX2::v_uint8x32> > >::MorphFilter'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./sample/sample (12).jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m img \u001b[38;5;241m=\u001b[39m binary_image(image)\n\u001b[1;32m----> 6\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcontour_dilation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# image=perspective_transform(image,0)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# # Apply adaptive thresholding\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# cv2.waitKey(0)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# cv2.destroyAllWindows()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 25\u001b[0m, in \u001b[0;36mcontour_dilation\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontour_dilation\u001b[39m(img) :\n\u001b[0;32m     22\u001b[0m      kernel \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[0;32m     23\u001b[0m           \u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     24\u001b[0m      ])\n\u001b[1;32m---> 25\u001b[0m      img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m      cf\u001b[38;5;241m.\u001b[39mshow_images([img])\n\u001b[0;32m     27\u001b[0m      \u001b[38;5;28mprint\u001b[39m(img)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:/a/opencv-python/opencv-python/opencv/modules/imgproc/src/morph.simd.hpp:649: error: (-215:Assertion failed) _kernel.type() == CV_8U in function 'cv::opt_AVX2::`anonymous-namespace'::MorphFilter<struct cv::opt_AVX2::`anonymous namespace'::MaxOp<unsigned char>,struct cv::opt_AVX2::A0x7e9a5f2b::MorphVec<struct cv::opt_AVX2::`anonymous namespace'::VMax<struct cv::hal_AVX2::v_uint8x32> > >::MorphFilter'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Read the grayscale image\n",
    "image = cv2.imread(\"./sample/sample (12).jpg\")\n",
    "img = binary_image(image)\n",
    "img = contour_dilation(img)\n",
    "# image=perspective_transform(image,0)\n",
    "# gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# # Apply adaptive thresholding\n",
    "# thresh_image = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY,91, 5)\n",
    "\n",
    "# # Show the original and thresholded images\n",
    "# # cv2.imshow(\"Original Image\", image)\n",
    "# cf.show_images([image,thresh_image])\n",
    "# # cv2.imshow(\"Thresholded Image\", thresh_image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
